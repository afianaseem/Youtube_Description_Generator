{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bf15b05-bc0e-4871-ab30-127486686239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Temp folder set to: E:/temp\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Set temp to E drive\n",
    "custom_temp = \"E:/temp\"\n",
    "os.makedirs(custom_temp, exist_ok=True)\n",
    "tempfile.tempdir = custom_temp\n",
    "os.environ[\"TMP\"] = custom_temp\n",
    "os.environ[\"TEMP\"] = custom_temp\n",
    "\n",
    "print(\"✅ Temp folder set to:\", tempfile.gettempdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "980b2fdf-92be-435e-bf66-d33b4bae147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Free space in temp: 49123 MB\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "free = shutil.disk_usage(tempfile.gettempdir()).free\n",
    "print(f\"📂 Free space in temp: {free // (1024 ** 2)} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "532a21d0-58cc-44b2-90be-1cba95a47290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\afi\\anaconda3\\lib\\site-packages (5.34.2)\n",
      "Requirement already satisfied: openai in c:\\users\\afi\\anaconda3\\lib\\site-packages (1.91.0)\n",
      "Requirement already satisfied: yt_dlp in c:\\users\\afi\\anaconda3\\lib\\site-packages (2025.6.9)\n",
      "Requirement already satisfied: ffmpeg-python in c:\\users\\afi\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\afi\\anaconda3\\lib\\site-packages (2.32.2)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (0.115.13)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (0.6.0)\n",
      "Requirement already satisfied: gradio-client==1.10.3 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (1.10.3)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (0.33.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (1.26.2)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: packaging in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (2.5.3)\n",
      "Requirement already satisfied: pydub in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio) (0.34.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from gradio-client==1.10.3->gradio) (2024.2.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from gradio-client==1.10.3->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.14.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.3.5)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\afi\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\afi\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: future in c:\\users\\afi\\anaconda3\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to e:\\temp\\pip-req-build-qqa24ov_\n",
      "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: more-itertools in c:\\users\\afi\\anaconda3\\lib\\site-packages (from openai-whisper==20250625) (10.1.0)\n",
      "Requirement already satisfied: numba in c:\\users\\afi\\anaconda3\\lib\\site-packages (from openai-whisper==20250625) (0.59.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from openai-whisper==20250625) (1.26.2)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\afi\\anaconda3\\lib\\site-packages (from openai-whisper==20250625) (0.9.0)\n",
      "Requirement already satisfied: torch in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from openai-whisper==20250625) (2.4.1+cpu)\n",
      "Requirement already satisfied: tqdm in c:\\users\\afi\\anaconda3\\lib\\site-packages (from openai-whisper==20250625) (4.66.4)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from numba->openai-whisper==20250625) (0.42.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper==20250625) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper==20250625) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from torch->openai-whisper==20250625) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\afi\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20250625) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from torch->openai-whisper==20250625) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from torch->openai-whisper==20250625) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from torch->openai-whisper==20250625) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from torch->openai-whisper==20250625) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\afi\\anaconda3\\lib\\site-packages (from torch->openai-whisper==20250625) (69.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch->openai-whisper==20250625) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from sympy->torch->openai-whisper==20250625) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\afi\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->openai-whisper==20250625) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'E:\\temp\\pip-req-build-qqa24ov_'\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio openai yt_dlp ffmpeg-python requests\n",
    "!pip install git+https://github.com/openai/whisper.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8d7cede-4088-4317-b556-df399599dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import tempfile\n",
    "import os\n",
    "import subprocess\n",
    "import whisper\n",
    "import requests\n",
    "import yt_dlp\n",
    "import textwrap\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import base64\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63521d11-4cec-4c39-91fc-5ed3be39b04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "🔒 Please enter your OpenRouter API key (input hidden):  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "from openai import OpenAI  # Ensure correct import based on your OpenAI library version\n",
    "\n",
    "# Securely prompt user for their OpenRouter API key\n",
    "api_key = getpass.getpass(\"🔒 Please enter your OpenRouter API key (input hidden): \")\n",
    "\n",
    "# Initialize the OpenAI-compatible client for OpenRouter\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa158c3b-e2dc-4b13-8c62-161e81fc25a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = whisper.load_model(\"base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5626e3b6-d022-433e-b08c-ab2701a2c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_video(youtube_url):\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    output_path = os.path.join(temp_dir, \"video.%(ext)s\")\n",
    "\n",
    "    ydl_opts = {\n",
    "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4',\n",
    "        'merge_output_format': 'mp4',\n",
    "        'ffmpeg_location': r'C:\\Users\\AFI\\Downloads\\ffmpeg-7.0.2-essentials_build\\bin\\ffmpeg.exe',\n",
    "        'outtmpl': output_path,\n",
    "        'quiet': True,\n",
    "        'noplaylist': True\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "\n",
    "    downloaded_file = output_path.replace(\"%(ext)s\", \"mp4\")\n",
    "    if not os.path.exists(downloaded_file):\n",
    "        raise FileNotFoundError(\"Video download failed.\")\n",
    "    return downloaded_file\n",
    "\n",
    "\n",
    "def download_direct_video(url):\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        temp_video = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\")\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            temp_video.write(chunk)\n",
    "        temp_video.close()\n",
    "        return temp_video.name\n",
    "    else:\n",
    "        raise ValueError(\"Failed to download video from URL.\")\n",
    "\n",
    "\n",
    "def is_valid_video(video_path):\n",
    "    try:\n",
    "        result = subprocess.run([\"ffmpeg\", \"-v\", \"error\", \"-i\", video_path, \"-f\", \"null\", \"-\"],\n",
    "                                stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        return result.returncode == 0\n",
    "    except Exception:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef36a313-ba57-48ff-8dc3-ad02d3726c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_video(video_path):\n",
    "    result = whisper_model.transcribe(video_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "def extract_key_frames(video_path, num_frames=1, max_dim=256):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    selected_frames = []\n",
    "    if total_frames == 0:\n",
    "        return []\n",
    "    step = max(total_frames // (num_frames + 1), 1)\n",
    "\n",
    "    for i in range(1, num_frames + 1):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)\n",
    "        success, frame = cap.read()\n",
    "        if success:\n",
    "            h, w = frame.shape[:2]\n",
    "            scale = max_dim / max(h, w)\n",
    "            resized = cv2.resize(frame, (int(w * scale), int(h * scale)))\n",
    "            _, buffer = cv2.imencode(\".jpg\", resized, [int(cv2.IMWRITE_JPEG_QUALITY), 50])\n",
    "            b64_image = base64.b64encode(buffer.tobytes()).decode('utf-8')\n",
    "            selected_frames.append(f\"data:image/jpeg;base64,{b64_image}\")\n",
    "    cap.release()\n",
    "    return selected_frames\n",
    "\n",
    "def describe_video_with_images(images_b64):\n",
    "    descriptions = []\n",
    "    for img_b64 in images_b64:\n",
    "        prompt = f\"\"\"\n",
    "You are a professional scriptwriter for iboothme Creative, mimicking their exact YouTube description style.\n",
    "\n",
    "The audio track had no usable speech, so you're analyzing the visual content.\n",
    "\n",
    "Follow this structure exactly (no headings):\n",
    "- First line: metadata view count and upload date, with hashtags if available.\n",
    "- Next three lines:\n",
    "  📩 info@iboothme.com  \n",
    "  📞 +971 4 448 8563  \n",
    "  👉🏼 https://www.iboothme.com\n",
    "\n",
    "- Title line: product name + subtitle + hashtags.\n",
    "\n",
    "- Greeting: \"Hi everyone, Welcome to the iboothme Channel.\"\n",
    "\n",
    "- A paragraph describing the product, tech, and guest experience (1–2 sentences).\n",
    "\n",
    "- A paragraph with use cases or extra promotions.\n",
    "\n",
    "- A line to subscribe or learn more.\n",
    "\n",
    "- Optionally a link (Instagram/location/brochure) if relevant.\n",
    "\n",
    "- At end: 3–7 related hashtags or keyphrases.\n",
    "\n",
    "Image for reference (base64 JPEG):\n",
    "\\\"\\\"\\\"{img_b64}\\\"\\\"\\\"\n",
    "\n",
    "Now generate the full description exactly in this style. Do not repeat any parts.\n",
    "\"\"\"\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"mistralai/mistral-7b-instruct:free\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=500,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        result = resp.choices[0].message.content.strip()\n",
    "\n",
    "        # Remove accidental duplication\n",
    "        first_half = result[:len(result)//2]\n",
    "        if result.endswith(first_half):\n",
    "            descriptions.append(first_half.strip())\n",
    "        else:\n",
    "            descriptions.append(result)\n",
    "\n",
    "    return descriptions[0] if descriptions else \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "416b49ad-e0f1-447e-81be-a23526cae306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcript(text):\n",
    "    lines = text.splitlines()\n",
    "    filtered = [line for line in lines if \"iboothme.com\" not in line and \"+971\" not in line]\n",
    "    return \"\\n\".join(filtered).strip()\n",
    "\n",
    "def generate_with_openrouter(transcript_chunk):\n",
    "    prompt = f\"\"\"\n",
    "You are a professional scriptwriter for iboothme Creative, mimicking their exact YouTube description style.\n",
    "\n",
    "Follow this structure exactly (no headings):\n",
    "- First line: metadata view count and upload date, with hashtags if available.\n",
    "- Next three lines:\n",
    "  📩 info@iboothme.com  \n",
    "  📞 +971 4 448 8563  \n",
    "  👉🏼 https://www.iboothme.com\n",
    "\n",
    "- Title line: product name + subtitle + hashtags.\n",
    "\n",
    "- Greeting: \"Hi everyone, Welcome to the iboothme Channel.\"\n",
    "\n",
    "- A paragraph describing the product, tech, and guest experience (1–2 sentences).\n",
    "\n",
    "- A paragraph with use cases or extra promotions.\n",
    "\n",
    "- A line to subscribe or learn more.\n",
    "\n",
    "- Optionally a link (Instagram/location/brochure) if relevant.\n",
    "\n",
    "- At end: 3–7 related hashtags or keyphrases.\n",
    "\n",
    "Transcript (for reference):\n",
    "\\\"\\\"\\\"{transcript_chunk}\\\"\\\"\\\"\n",
    "\n",
    "Now generate the full description exactly in this style.\n",
    "\"\"\"\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"mistralai/mistral-7b-instruct:free\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=500,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "276fa821-b702-4818-8ea1-aed4453d3e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_description(input_mode, video_file, video_url):\n",
    "    try:\n",
    "        if input_mode == \"Upload\":\n",
    "            if not video_file:\n",
    "                return \"Please upload a video file.\"\n",
    "            if isinstance(video_file, str) and os.path.exists(video_file):\n",
    "                video_path = video_file\n",
    "            else:\n",
    "                with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as temp:\n",
    "                    temp.write(video_file.read())\n",
    "                    video_path = temp.name\n",
    "        elif input_mode == \"URL\":\n",
    "            if not video_url:\n",
    "                return \"Please enter a video URL.\"\n",
    "            if \"youtube.com\" in video_url or \"youtu.be\" in video_url:\n",
    "                video_path = download_youtube_video(video_url)\n",
    "            else:\n",
    "                video_path = download_direct_video(video_url)\n",
    "        else:\n",
    "            return \"Invalid input mode.\"\n",
    "\n",
    "        if not is_valid_video(video_path):\n",
    "            return \"Error: The uploaded or downloaded video is not valid.\"\n",
    "\n",
    "        transcript = transcribe_video(video_path).strip()\n",
    "\n",
    "        if transcript:\n",
    "            chunks = textwrap.wrap(transcript, 1500)\n",
    "            result_parts = [generate_with_openrouter(chunk) for chunk in chunks[:1]]\n",
    "            result = \"\\n\\n\".join(result_parts)\n",
    "        else:\n",
    "            frames_b64 = extract_key_frames(video_path)\n",
    "            if not frames_b64:\n",
    "                result = \"Error: No usable audio or video content found.\"\n",
    "            else:\n",
    "                result = describe_video_with_images(frames_b64)\n",
    "\n",
    "        if os.path.exists(video_path):\n",
    "            os.remove(video_path)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77f72559-5215-456a-a98b-02bcf1ecbb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* Running on public URL: https://99a370b0add0c60d7a.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] oEjVunPv6HI: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n",
      "WARNING: [youtube] oEjVunPv6HI: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AFI\\anaconda3\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AFI\\anaconda3\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AFI\\anaconda3\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AFI\\anaconda3\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as interface:\n",
    "    gr.Markdown(\"## 🎥 iboothme Creative – Description Generator\")\n",
    "    gr.Markdown(\"Upload a video or paste a YouTube URL (metadata pulled automatically).\")\n",
    "\n",
    "    input_mode = gr.Radio([\"Upload\", \"URL\"], value=\"Upload\")\n",
    "    video_file = gr.Video(visible=True)\n",
    "    video_url = gr.Textbox(label=\"Video URL\", visible=False)\n",
    "\n",
    "    output_text = gr.Textbox(label=\"Generated Description\", lines=12)\n",
    "\n",
    "    def toggle(mode):\n",
    "        return gr.update(visible=(mode==\"Upload\")), gr.update(visible=(mode==\"URL\"))\n",
    "\n",
    "    input_mode.change(toggle, input_mode, outputs=(video_file, video_url))\n",
    "\n",
    "    gr.Button(\"Generate\").click(\n",
    "        fn=generate_description,\n",
    "        inputs=[input_mode, video_file, video_url],\n",
    "        outputs=output_text\n",
    "    )\n",
    "\n",
    "interface.launch(share=True, inline=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f747983-4245-46f6-8921-d7cf17871eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
